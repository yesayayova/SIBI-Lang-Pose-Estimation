{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08de0a60",
   "metadata": {},
   "source": [
    "# Membuat Dataset yang diperlukan\n",
    "\n",
    "Pada notebook ini, kalian akan diarahkan bagaimana membuat atau menambahkan dataset SIBI language sesuai dengan keinginan kalian. Adapun library yang diperlukan pada notebook ini antara lain\n",
    "\n",
    "<ul>\n",
    "    <li>pandas</li>\n",
    "    <li>numpy</li>\n",
    "    <li>opencv</li>\n",
    "    <li>mediapipe</li>\n",
    "    <li>csv</li>\n",
    "    <li>pickle</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4afd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e40382",
   "metadata": {},
   "source": [
    "## Menggunakan Library Mediapipe untuk Pose Estimation \n",
    "\n",
    "Pada project ini, digunakan library mediapipe yang dapat membantu kita dalam melakukan pose estimation, yaitu sebuah pekerjaan pada CV untuk menentukan posisi setiap titik-titik penting pada anggota tubuh. Pada sesi ini kita gunakan pose estimation untuk jari-jari kita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "274a0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a88138e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(model_complexity=0, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    \n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f688d159",
   "metadata": {},
   "source": [
    "## Pengambilan Dataset\n",
    "\n",
    "Dataset pada project ini berupa video rekaman kalian yang menunjukkan beberapa posisi jari yang melambangkan beberapa kata atau huruf pada SIBI Language. Adapun SIBI language adalah salah satu bahasa isyarat yang dipergunakan di Indonesia. Adapun yang perlu kalian perhatikan dalam pengambilan dataset\n",
    " \n",
    " 1. Tentukan dahulu, huruf atau kata apa yang akan kalian peragakan. \n",
    " 2. Usahakan posisi jari-jari kalian terlihat jelas pada webcam kalian. \n",
    " 3. lama durasi pada setiap recording label dapat disesuaikan kebutuhan (untuk dataset yang sudah ada dilakukan rekaman kurang lebih 40 detik pada setiap label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0905105",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = 'Halo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3c9488be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variable for hand keypoints data\n",
    "hand_keypoint_data = np.array([])\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    # Read until video is completed\n",
    "  while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "    \n",
    "    try:\n",
    "      # To improve performance, optionally mark the image as not writeable to\n",
    "      # pass by reference.\n",
    "      image.flags.writeable = False\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      results = hands.process(image)\n",
    "\n",
    "      # Draw the hand annotations on the image.\n",
    "      image.flags.writeable = True\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "      if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "          mp_drawing.draw_landmarks(\n",
    "              image,\n",
    "              hand_landmarks,\n",
    "              mp_hands.HAND_CONNECTIONS,\n",
    "              mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "              mp_drawing_styles.get_default_hand_connections_style())\n",
    "      \n",
    "      # Checking keypoints if complete will do this block of code\n",
    "      if len(results.multi_hand_landmarks[0].landmark) >= 21:\n",
    "        # define variable for centering and scaling process\n",
    "        centering = np.array([])\n",
    "        scaling = np.array([])\n",
    "\n",
    "        # Centering X coordinate Process\n",
    "        for indexPoint in range(21):\n",
    "          centering = np.append(centering, (\n",
    "            results.multi_hand_landmarks[0].landmark[0].x - results.multi_hand_landmarks[0].landmark[indexPoint].x))\n",
    "\n",
    "        # Centering Y coordinate Process\n",
    "        for indexPoint in range(21):\n",
    "          centering = np.append(centering, (\n",
    "            results.multi_hand_landmarks[0].landmark[0].y - results.multi_hand_landmarks[0].landmark[indexPoint].y))\n",
    "\n",
    "        centering = centering.reshape(2, 21)\n",
    "        \n",
    "        # Scaling Process\n",
    "        for indexIter in range(2):\n",
    "          for jointIter in range(21):\n",
    "            scaling = np.append(scaling, centering[indexIter][jointIter] / np.max(\n",
    "              np.absolute(centering[indexIter])) * 320)\n",
    "        \n",
    "        # Normalization Process\n",
    "        for jointIter in range(42):\n",
    "          hand_keypoint_data = np.append(hand_keypoint_data, (scaling[jointIter] + 320))\n",
    "\n",
    "        # Write spatiodata from hand keypoints coordinate\n",
    "        if len(hand_keypoint_data) >= 210:\n",
    "          # Write spatiodata to csv\n",
    "          with open('./data/data_'+ label_data + '.csv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            writer.writerow(hand_keypoint_data)\n",
    "\n",
    "          # deleted 42 old data \n",
    "          deletedIndex = np.arange(42)\n",
    "          hand_keypoint_data = np.delete(hand_keypoint_data, deletedIndex)\n",
    "\n",
    "    except Exception as e:\n",
    "      continue\n",
    "\n",
    "    finally:\n",
    "      # Show the result\n",
    "      cv2.imshow('Result', image)\n",
    "\n",
    "      if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "21deba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb402991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('media-pipe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b643dba08d8858f3d28aeaaf9d44ff471e6db43df59d5b28d4de16226bfcac4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

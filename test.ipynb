{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menjalankan Hasil Model Training\n",
    "\n",
    "Pada notebook ini kalian akan diarahkan untuk menjalankan model yang telah kalian dapatkan dari proses training nih! Adapun library yang dibutuhkan untuk notebook ini adalah\n",
    "\n",
    "<ul>\n",
    "    <li>Pandas</li>\n",
    "    <li>Numpy</li>\n",
    "    <li>OpenCV</li>\n",
    "    <li>Mediapipe</li>\n",
    "    <li>CSV</li>\n",
    "    <li>Pickle</li>\n",
    "    <li>Scikit Learn</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library and framework\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Membaca Model ML yang Telah Disimpan dalam Bentuk .sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\media-pipe\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator SVC from version 1.0.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tentukan path dari model hasil training kalian\n",
    "model_path = './model/mymodel2.sav'\n",
    "\n",
    "with open(model_path, 'rb') as file:\n",
    "    action_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jalankan Saja Programnya\n",
    "Silakan kalian jalankan program berikut dan peragakan semua label yang telah kalian latih! pastikan semua dapat dibaca oleh komputer. Bila bisa semua label, selamat! kalian telah berhasil mengembangkan project CV yang kecee ini! Untuk lebih jelasnya mengenai apasaja yang ada pada Computer Vision, dapat kalian pelajari pada sesi pembelajaran Computer Vision, sampai jumpa lagi!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Define global variable for hand keypoints data\n",
    "hand_keypoint_data = np.array([])\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    # Read until video is completed\n",
    "  while cap.isOpened():\n",
    "    # Capture frame-by-frame\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "    \n",
    "    try:\n",
    "      # To improve performance, optionally mark the image as not writeable to\n",
    "      # pass by reference.\n",
    "      image.flags.writeable = False\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      results = hands.process(image)\n",
    "\n",
    "      # Draw the hand annotations on the image.\n",
    "      image.flags.writeable = True\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "      if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "          mp_drawing.draw_landmarks(\n",
    "              image,\n",
    "              hand_landmarks,\n",
    "              mp_hands.HAND_CONNECTIONS,\n",
    "              mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "              mp_drawing_styles.get_default_hand_connections_style())\n",
    "      \n",
    "      # Checking keypoints if complete will do this block of code\n",
    "      if len(results.multi_hand_landmarks[0].landmark) >= 21:\n",
    "        # define variable for centering and scaling process\n",
    "        centering = np.array([])\n",
    "        scaling = np.array([])\n",
    "\n",
    "        # Centering X coordinate Process\n",
    "        for indexPoint in range(21):\n",
    "          centering = np.append(centering, (\n",
    "            results.multi_hand_landmarks[0].landmark[0].x - results.multi_hand_landmarks[0].landmark[indexPoint].x))\n",
    "\n",
    "        # Centering Y coordinate Process\n",
    "        for indexPoint in range(21):\n",
    "          centering = np.append(centering, (\n",
    "            results.multi_hand_landmarks[0].landmark[0].y - results.multi_hand_landmarks[0].landmark[indexPoint].y))\n",
    "\n",
    "        centering = centering.reshape(2, 21)\n",
    "        \n",
    "        # Scaling Process\n",
    "        for indexIter in range(2):\n",
    "          for jointIter in range(21):\n",
    "            scaling = np.append(scaling, centering[indexIter][jointIter] / np.max(\n",
    "              np.absolute(centering[indexIter])) * 320)\n",
    "        \n",
    "        # Normalization Process\n",
    "        for jointIter in range(42):\n",
    "          hand_keypoint_data = np.append(hand_keypoint_data, (scaling[jointIter] + 320))\n",
    "\n",
    "        # Write spatiodata from hand keypoints coordinate\n",
    "        if len(hand_keypoint_data) >= 210:\n",
    "          labels = [file[5:-4] for file in os.listdir('data')]\n",
    "           \n",
    "          prediction = action_model.predict([hand_keypoint_data])\n",
    "\n",
    "          deletedIndex = np.arange(42)\n",
    "          hand_keypoint_data = np.delete(hand_keypoint_data, deletedIndex)\n",
    "\n",
    "          cv2.putText(image,f'{labels[prediction[0]]}', (10,50), cv2.FONT_HERSHEY_SIMPLEX, 2, (100, 255, 0), 3, cv2.LINE_AA)\n",
    "         \n",
    "    except Exception as e:\n",
    "      continue\n",
    "\n",
    "    finally:\n",
    "      # Show the result\n",
    "      cv2.imshow('Result', image)\n",
    "\n",
    "      if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('media-pipe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b643dba08d8858f3d28aeaaf9d44ff471e6db43df59d5b28d4de16226bfcac4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
